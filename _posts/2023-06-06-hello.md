
## Brief Introduction 
> Latent Dirichlet Allocation, LDA - 디리클레 분포를 이용한 베이즈 추론  

	
###   Latent 
  
우리가 글을 쓸 때는 먼저 주제를 선정하고, 그 주제에 관련된 단어를 선택하여 글을 써내려갈 것이다. 따라서 단어는 주제와 밀접한 관련이 있고 주제가 변하면 단어들의 구성도 달라지게 된다.   만약 우리가 사전정보 없이 어떤 문서가 주어지고 이 글이 무엇에 대한 글인지 추론한다고 가정해보자. 우리는 글이 쓰여진 세부과정을 모른 채 그 과정의 결과인 문서의 단어들만을 가지고 어떤 주제일지 추론해야 한다. (글쓰는 과정과 반대로 생각한다고 볼 수 있다.)   
  따라서    **Latent**의 의미는 문서에서 숨겨진 주제를 발견하는 것을 말한다. 
  
### Dirichlet 

 문서의 숨겨진 주제를 찾기 위해 문서가 어떤 주제일 가능성을 확률로 나타내고자 한다. 
>   나폴리탄은 개항기 양식 문화와 함께 유입된 이래 일본에서 독자적으로 진화한 스파게티다. 일본에서는 어린시절을 연상시키는 ‘추억의 음식’ 으로 꼽히면서 미트소스와 함께 대표적인 스파게티로 폭넓은 사랑을 받고 있다. 뉴 그랜드 호텔의 주방장이 스파게티에 케첩을 뿌려 먹는 미군을 보고 메뉴를 개발한 뒤, 토마토 산지인 이탈리아 나폴리의 이름을 따서 ‘나폴리탄’이라고 부르기 시작했다고 한다. 2009년 요코하마 세관이 요코하마 뉴 그랜드 호텔의 정보를 바탕으로 ‘나폴리탄은 전후 요코하마에서 탄생했다’는 문서를 발표한 것이 나폴리탄 축제의 시발점이 됐다.
-문화일보

  위 글을 보면 나폴리탄, 토마토, 케첩 나폴리 등의 단어가 자주 등장한다. 아마 까르보나라 스파게티였다면 크림, 베이컨, 치즈 등의 단어가 자주 등장했을 것이다. 그렇다면 위 글은 나폴리탄스파게티의 주제일 가능성이 높고 까르보나라 스파게티가 주제일 가능성은 낮다. 
  
 따라서 문서에서 발견되는 단어들을 관찰하여 
  
+ 문서가 어떤 주제인지에 대한 확률 : 문서의 주제분포(Document-Topic distribution)
+ 그 주제가 어떤 단어들의 분포로 이루어져 있는가 : 주제의 단어분포(Topic-Word distribution)  
 
위의 두 분포가 모두 디리클레 분포를 따른다고 가정한다. 

<u>왜 디리클레 분포를 사용하는가?</u>
어떤 주제에 대해 글을 쓸 때, n가지의 주제 중 하나를 선택하고 그 주제에 포함된 단어가 m개라면 그 중 하나를 선택하는 것도 다항분포이다. 
해당 문서가 어떤 주제인지에 대한 확률, 그 단어가 선택될 확률 등을 모르는 상황이기 때문에 일단 사전 확률을 정한다. 그리고 문서의 모든 단어, 다른 문서들의 모든 단어를 관찰하면서 문서의 주제분포와 각 주제의 단어분포를 다시 계산하여 사후분포를 얻는다. 
사전/사후 확률분포가 같은 가족군일 때 켤레분포라고 하며 사전분포가 켤레사전분포일 때 사후 분포 업데이트의 계산이 편리해 지므로 켤레사전분포를 사전분포로 선택한다. 
따라서 다항분포의 사전켤레분포인 디리클레 분포를 사용한다. 
   
 
  
###   Allocation 

토픽모델의 최종 목표인 주어진 문서에 주제를 할당하는 것을 말한다. 
이를 위해서는 '문서의 i번째 단어가 어떤 토픽에 속하는가'를 결정해야한다.

0) 모든 단어에 주제를 랜덤하게 할당한다. (초기에는 랜덤배정)
1) i번째 단어를 지우고 위에서 만들어진 분포들을 통해 문서의 나머지 단어들이 어떤 주제에 배정되어있는지 본다. 
2) 나머지 단어들을 보고 이 문서의 주제분포와 주제의 단어분포를 계산한다.
3) 두 분포를 기반으로 i번째 단어가 어떤 주제에 할당될지 확률을 계산한다. 
4) 모든 단어에 대해 이 과정을 반복하면서 분포를 업데이트 한다. 

위의 할당 과정을 반복하면 변동 없이 수렴하는 순간이 오면 멈추고 단어들의 주제분포를 이용하여 해당 문서에 주제를 할당한다.

3개의 주제가 있다고 가정 :  
['나폴리탄스파게티', '까르보나라스파게티', '알리오올리오']
현재 문서 : 
['나폴리탄', '양식', '문화', '일본', '스파게티', '토마토'] 



  - 베이즈 추론
 어떤 사건에 대해 어떠한 확률로 발생할 것이라고 믿어본다(사전확률분포) -> 사건을 관측해서 추가정보를 얻는다 -> 얻은 정보에 맞도록 가정을 수정한다(사후확률분포)
 
  ▷ 정확한 확률분포를 모르는 상태에서 사건을 관측하며 확률분포를 개선해나감

   토픽모델링에 적용 시 : 이 글은 나폴리탄스파게티 관련 주제일 것 같아 -> 나폴리탄스파게티 관련 단어들이 나왔나 보자 -> 그 주제가 맞는듯ㅇㅇ 
   
 

 
   



#### Evaluation in Topic Modeling

이 과정에서 적정토픽의 갯수를 추정하기 위해 **Held-out likelihood**(지속성: 데이터의 일부가 존재하지 않을 때에도 모형의 예측력이 여전히 지속되는가를 테스트 한 지표), 잔차, 의미적 응집성 지수들이 사용되었다. 토픽이 추정되고 나면 각 문서에서의 토픽의 발현확률과 토픽을 구성하는 단어들의 시퀀스를 통해 토픽의 이름을 정하게 된다. 이 연구에서는 연구자 2명의 일치도를 토대로 토픽을 선별하고 각 주제들을 잘 나타내는 이름을 선정하였다. 이때 표본에서 선택되지 않은 "보류"단어 집합을 통해 모델의 이름을 선정하는데 활용하였다. 토픽의 이름을 확정하고 추가적인 분석을 위해 관심변수인 성별, 연령, 학력 등의 개인차 변수를 통해 각 항목에서의 토픽의 비율과 생성확률을 비교하였다.

1. 토픽의 수 결정적정한 토픽갯수를 추정하고 진단하기 위해 Held-out likelihood(모델의 지속성 평가지수), 잔차, 의미적응집성 지수들을 사용하였다. 적정토픽 갯수를 진단하기 위한 지표들을 교차 검증하여 hold-out(지속가능성) 샘플 간의 적합성을 최적화 한 여러 주제로 최종 모델을 선택하였다. 잠재 토픽 개수의 범위를 설정한 뒤 잠재 토픽 개수에 따라 진단지수들의 값이 어떻게 변하는지 살펴보는 과정을 반복적으로 시행하였는데. 잠재 토픽의 개수를 3부터 10까지 1의 간격으로 토픽의 개수를 변화시키며 관련 지표들의 변화를 확인하였다. [그림 2]의 그래프에서 확인할 수 있듯 ** 잠재 토픽의 개수가 다섯 개일 때, 모형의 지속성이 가장 높고, 잔차의 분포가 작게 나타나 데이터의 적합도가 높은 것으로 판독되었다.** 이를 통해 최종적으로 응답자들의 진술에서 나타난 주제를 가장 잘 표현하는 5개의 토픽을 가진 모델이 선택되었다. 


 토픽 모델링은 비지도 학습을 통해 토픽들을 추출하고 군집화하는데 다른 비지도 학습과 다르게 훈련 및 시험 데이터 셋이 존재하지 않아 모형의 성능을 비교평가하기 어려운 면이 있어 적절한 토픽의 개수를 산출하기 것이 중요하다[9, 10]. 이를 위해, 최대우도 추정치(Held-out likelihood)와 잔차(Residual)을 활용하여 토픽의 개수를 최적화 시키는 것이 일반적이다. 하지만 토픽의 개수가 점점 증가함에 따라 추정치와 잔차의 성능은 개선되는 반면 토픽들의 의미론적 일관성을 나타내는 평가지표(Semantic coherence)가 낮아지는 문제가 발생한다. 이와같은 이유로 인해 토픽의 개수 및 각 토픽들이 갖는 의미들에 대한 부분들은 사용자가 직접 판별하여 선택해야 한다[11, 12, 13]. __본 논문에서는 추정치, 잔차, 의미론적 일관성에 대한 지표를 통해 추정치와 잔차가 극소점에서 가깝고 의미론적 일관성이 최소화 되지 않는 지점을 기준으로 최적 토픽 개수를 결정__하였으며, 최종적으로 17개의 토픽 개수를 도출하였다. 
 
 10.3.1 주제의 수(K) 설정
주제를 몇개로 설정할지 탐색한다. 7개와 10개를 놓고 비교해보자. searchK()함수는 주제의 수에 따라 4가지 계수를 제공한다.

배타성(exclusivity): 특정 주제에 등장한 단어가 다른 주제에는 나오지 않는 정도. 확산타당도에 해당.

의미 일관성(semantic coherence): 특정 주제에 높은 확률로 나타나는 단어가 동시에 등장하는 정도. 수렴타당도에 해당.

지속성(heldout likelihood): 데이터 일부가 존재하지 않을 때의 모형 예측 지속 정도.

잔차(residual): 투입한 데이터로 모형을 설명하지 못하는 오차.

배타성, 의미 일관성, 지속성이 높을 수록, 그리고 잔차가 작을수록 모형의 적절성 증가.

보통 10개부터 100개까지 10개 단위로 주제의 수를 구분해 연구자들이 정성적으로 최종 주제의 수 판단한다.



#### 토픽모델링의 평가
- Perplexity


- Semantic coherence 단어의 의미론적 응집도
- Held-out likelihood
- Residual

Held-out likelihood 

데이터 셋을 훈련용과 테스트용으로 나눠, 훈련용 셋의 토픽 분포가 테스트용 셋의 문서 및 어휘를 설명하는 확률 척도    


Held-out likelihood 값을 테스트용 셋의 단어 갯수로 나누고 양수 값으로 전환함으로서 척도 값이 작아질 수록 최적의 모델임 
![](https://velog.velcdn.com/images/voronoii/post/4e2365bf-ddf3-4557-8e46-bffd4f523fa3/image.png)


본 연구에서는 적절한 토픽 개수를 찾기 위해 R에서 제공하는 단어의 의미론적 응집도(semantic coherence)가 최소화되지 않으면서, 하한(lower bound) 및 최대우도 추정치(held-out likelihood)는 극대에, 그리고 잔차(residual)는 극소에 가까운 Fig. 2에 제시된 바와 같이 30개를 선정하였다[20].
(src : https://www.kais99.org/jkais/journal/Vol23No08/vol23no08p15.pdf)

토픽 모델링은 비지도 학습을 통해 토픽들을 추출하고 군집화하는데 다른 비지도 학습과 다르게 훈련 및 시험 데이터 셋이 존재하지 않아 모형의 성능을 비교평가하기 어려운 면이 있어 적절한 토픽의 개수를 산출하기 것이 중요하다[9, 10]. 이를 위해, 최대우도 추정치(Held-out likelihood)와 잔차(Residual)을 활용하여 토픽의 개수를 최적화 시키는 것이 일반적이다. 하지만 토픽의 개수가 점점 증가함에 따라 추정치와 잔차의 성능은 개선되는 반면 토픽들의 의미론적 일관성을 나타내는 평가지표(Semantic coherence)가 낮아지는 문제가 발생한다. 이와같은 이유로 인해 토픽의 개수 및 각 토픽들이 갖는 의미들에 대한 부분들은 사용자가 직접 판별하여 선택해야 한다.
(src : https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE09215450)


#### 재미있어 보이는 주제
텍스트 스트리밍 데이터의 토픽모델링
실시간 토픽모델링
Structured Topic Modeling
* LDA 기법은 메타데이터를 활용하지 않고, 토픽을 추출할 때 문서 내의 빈도수를 기반으로 하므로 부정확한 결과를 도출할 수 있다는 단점이 존재한다. 이러한 제한점을 해결하기 위해 STM이 제안되었다. STM은 LDA의 확장된 모형으로 문서에 메타데이터를 활용하여 토픽을 구성하는 단어들의 분포를 결정한다. 이에 따라 STM은 메타 데이터와 문서 내에 존재하는 토픽들의 상관관계에 대해 추정할 수 있고, 각 토픽들의 관계를 구분하여 해석할 수 있다는 장점이 있다



